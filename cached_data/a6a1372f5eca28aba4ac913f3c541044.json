"ship re saher section 6\n\nMFML (essigmentent i)\n- Q1. Using only the idea that in the equation \\( C=A B \\) where \\( C, A, B \\) are \\( n \\times n \\) matrices, the ith row of the matrix \\( C \\) for \\( 1 \\leq i \\leq n \\) is eletained by taking a linear combination of the wous of \\( B \\) where the combining coefficients comefrom the ith row of \\( A \\), show that the inverse of a lower triangular matrix is a lower triangular matrix.\n\\( \\rightarrow \\) quien \\( C=A B \\), where \\( A, B \\& C \\) are \\( n \\times n \\) matrices. each element of \\( C \\) can be expressed as\n\\[\nC_{i j}=\\sum_{k=1}^{n} A_{i k} B_{k j}\n\\]\n\\( \\Rightarrow \\) we netd to prove if \\( A \\) is a lower triangular matrix, \\( \\Rightarrow \\) then \\( A^{-1} \\) is also a lover triangular matrix.\n\\( \\Rightarrow \\) we know that,\n\\( \\qquad \\)\n\\( \\Rightarrow \\) ust assume,\n\\( A A^{1}=A^{-1} A=I \\) (from muttiplicative enverse of a square matrix) where \\( I \\) is the identity matrix of size \\( n \\times n \\).\n\\( \\Rightarrow \\) and \\( C=I(n x-n) \\), Idendity matrix.\n\\( \\Rightarrow \\) Then from \\( { }^{n} \\) eq, (1), we have\n\\[\nc_{i j}=\\sum_{k=1}^{n} a_{i k b k j}=\\left\\{\\begin{array}{ll}\n1 ; & i=j \\\\\n0 ; & i \\neq j\n\\end{array}\\right.\n\\]\n\\( \\Rightarrow \\rightarrow{ }^{2} \\rightarrow{ }_{i j} \\) is the sum of produets of elemente from the ith row of \\( A \\) and the jen column of \\( B \\).\n\nSripra saher\nSection 6\n\nDate: \\( \\square \\)\nQ2- If an integer \\( n \\) is an eigenvalue of square matrix where all elements of a matrix lelongs to the set of integers, then prove that determinant of that matrix is nk where \\( k \\) is an integer.\n\\( \\rightarrow \\) Let \\( A \\) le an \\( m \\times m \\) matrix with integer clements. The eigenvalue of \\( A \\) are the roots of its charateristipolynomi--al, given as\n\\[\nP(\\lambda)=\\operatorname{det}(A-\\lambda I) \\quad\\binom{I \\text { is the identity matrix }}{\\text { of the same size } m \\times m}\n\\]\n\\( \\because n \\) is an eigenvalue of \\( A \\), it is a roo ot of the charaderist polynomial,\n\\[\n\\therefore \\quad p(n)=\\operatorname{det}(A-n I)=0\n\\]\n\\( \\rightarrow \\) we also know that, Ine determinant of \\( A \\) can be expressed as the product of its eigenvalues. Lets say the eigenvalues are \\( \\lambda_{1}, \\lambda_{2}, \\ldots \\lambda_{n} \\).\n\\[\n\\therefore \\quad \\operatorname{det}(A)=\\lambda_{1}, \\lambda_{2}, \\lambda_{3} \\ldots \\lambda_{n}\n\\]\n\\( \\Rightarrow \\operatorname{since} \\lambda_{1}=n \\) (one of the rigenvalue)\n\\[\n\\therefore \\operatorname{def}(A)=n\\left(\\lambda_{2} \\cdot \\lambda_{3} \\cdots \\lambda_{n}\\right)\n\\]\n\\( \\Rightarrow \\rightarrow \\) Geien that \\( A \\) has all the integer elem ents, its charaderistic. poly\" \\( p(\\lambda) \\) has oncy integer coefficients.\nBy the properties of polynomials with integer coeff, the eigenralues of \\( A \\), must be either integer or comprex conjugate pairs (if non-real).\n\\( \\because \\) det of matrix with integer entries is an integer, we can denote \\( \\lambda_{1} \\cdot \\lambda_{2} \\ldots \\lambda_{n}=k \\) (an integer).\nas \\( n \\) is an rinteger, afte an integer. \\( \\therefore k \\) is an integer.\n\\[\n\\therefore \\quad \\operatorname{det}(A)=n K \\quad\\left(K=\\lambda 1 \\cdots \\lambda_{n}\\right)\n\\]\n\nSnipra sany Section 6\n\nDate:\nQ3. If \\( A \\) is a invertibe square matrix of order \\( n \\), then prove or disprove that \\( \\operatorname{rank}(A)=\\operatorname{rank}(A B) \\).\n\\( \\rightarrow \\) quien \\( A \\) is an inerertible \\( n \\times n \\) matrix.\nwe need to find whether\n\\( \\operatorname{rank}(A)=\\operatorname{rank}(A B) \\) for any \\( n \\times n \\) matrix \\( B \\).\nnow, since \\( A \\) is invertible, \\( A^{-1} \\) exists and \\( \\operatorname{rank}(A)=n \\) lonsidering the product \\( A B \\),\nmultiplying \\( A B \\) witen \\( A^{-1} \\) on the left, we get\n\\[\nA^{-1}(A B)=I B=B\n\\]\n\nThis shows \\( B \\) is equivalent to \\( A^{-1} A B \\).\nBy the rank preservation law, The rank of a matrix product incublung an invertible matrix is preserued.\n\\( \\therefore \\) since \\( A^{-1} \\) is invertible, multiplyins \\( A B \\) with \\( A^{-1} \\) does not change the rank of the produet \\( A B \\).\n\\[\n\\begin{array}{l}\n\\therefore \\operatorname{rank}(A B)=\\operatorname{rank}(A+A B)=\\operatorname{rank}(B) \\\\\n\\quad \\Rightarrow \\operatorname{rank}(A B)=\\operatorname{rank}(B)\n\\end{array}\n\\]\n\nInus for an invertible matrix \\( A \\), the rank of \\( A \\) does not infeuence the rank of \\( A B \\). Rank of \\( A B \\) is solely deter mined by the rank of matrix \\( B \\).\n\\( \\therefore \\) The statement, \\( \\operatorname{rank}(A)=\\operatorname{rank}(A B) \\) is not necessarily\ntrue.\nIf \\( B \\) has full rank \\( n \\), only then it can be true- In that case it will be \\( \\operatorname{rank}(A)=\\operatorname{rank}(A B)=\\operatorname{rank}(B) \\geq n \\)\n\nshipera sahy\nsection 6\n\\( \\rightarrow \\) Riagonal Elements:\nlets onsider the diagonal elements where ( \\( i i^{j} \\) )\n\\[\nC_{i L}^{i o}=\\sum_{K=1}^{i} a_{i k} b_{k i}=1 \\quad\\left(\\begin{array}{l}\n\\text { the sem is only } \\\\\n\\text { taken upto } i \\text { as } \\\\\na_{i k}=0 \\text { for } k>i\n\\end{array}\\right)\n\\]\n\\( \\rightarrow \\) Elements aboue the diagonal:\nLets consider the elements allove the diagonal, \\( (i<j) \\).\n\\[\nc_{i j}=\\sum_{k=1}^{t} a_{i k} b_{k j}=0 \\text { (3) } \\quad\\left[\\begin{array}{l}\n\\text { The sum is only taken } \\\\\n\\text { ipto } i \\text { as } a_{i k}=0 \\text { for } k>i\n\\end{array}\\right]\n\\]\n\nThis implies that \\( \\dot{B}_{k j}=0 \\) for \\( k>j \\) since \\( a_{i k} \\) is non-yero only for \\( k \\leq i \\). This ensures that cach element in the upper triangular part of \\( C \\) (where \\( i<j \\) ) is 0 .\n\\( \\left[\\begin{array}{c}\\text { Conclusion: Since } B i j=0 \\text { for } i<j \\text {, it follous that } \\\\ B=A^{+} \\text {is a lower triangular matrix. } \\\\ \\therefore \\text { the inverse of a triangular matrix is also a } \\\\ \\therefore \\text { tower triangular matrix. }\\end{array}\\right] \\) from eq (2)\n\\[\nc_{i i}=a_{i} i b i i=1 \\Rightarrow b_{i i}=1 / a i i\n\\]\nfrom eq(3) for \\( i>j, \\sum_{k=1}^{i} a_{i k} b_{k j}=0 \\Rightarrow a_{i}=b_{i} b_{i j}+\\sum_{k=1}^{i+1} a_{i k} b_{k j}=0 \\)\n\\[\n\\Rightarrow b_{i j}=-1 / a i \\sum_{k=1}^{1} a_{i k} b_{k j}\n\\]\nfor \\( i<j \\), substitutins \\( a_{i k}=0 \\Rightarrow b i j=0 \\)\n\\[\n\\therefore B_{i j}=\\left\\{\\begin{array}{ll}\n0 & , \\quad i<j \\\\\n1 / 9 i i, & i=j \\\\\n-1 / a i i \\sum_{k=1}^{i-1} a_{i k} b k j, & i>j\n\\end{array}\\right\\} \\rightarrow \\text { triangular }\n\\]\n\nSnipra Saner\nSection 6\n\nDate: \\( \\square \\)\nQ4. A macnine learning researcher comes across the following matrix whils analyzing dats from a leorning problem. He realizes that a carefue study of this matrix and its properties will hal him design a faster algo to solve the learning problem. In this matrix the value of \\( a=1 \\) and \\( b=-1 \\). He makes an interesting obs. that \\( A^{2}=8 I \\). He\n\\( \\Rightarrow \\) wants to find the ansuetr to the folloving questions. Derine \\( \\Rightarrow \\) the answer to the questions from the propertie of the \\( \\Rightarrow \\) matrix rather than doing long numerical computations \\( \\Rightarrow \\) involuins the fuel matrix.\n\\( \\Rightarrow \\) a) What are the eigen values of this matrix?\nb) what is the realue of the ratio \\( \\frac{\\lambda(\\max )}{\\lambda(\\min )} \\) ?\n\\( \\Rightarrow \\) Io find the cigenvalue of \\( A \\), we strould (min) with the given propierty, \\( \\quad A^{2}=8 I \\)\n\nLets consider the cigenvalue equation:\n\\( A x=\\lambda x \\), , is an eigenvalue \\& \\( x \\) is\n\\( \\Rightarrow \\) now, mutiplyins wotn sides of corresponding eigenvevor wion \\( A \\).\n\\[\n\\begin{aligned}\nA(A x) & =A(\\lambda x)=\\lambda(A x)=\\lambda(\\lambda x)=\\lambda^{2} x \\\\\n\\therefore \\quad A^{2} x & =\\lambda^{2} x\n\\end{aligned}\n\\]\nsubsituting \\( A^{2} \\) wiin \\( 8 I \\) as \\( \\left(A^{2}=8 I\\right) \\)\n\\[\n\\begin{aligned}\n8 I x & =\\lambda^{2} x \\\\\n\\Rightarrow \\lambda^{2} x & =8 x\n\\end{aligned}\n\\]\n\\( \\because x \\) is not the tero weitor, we can equate the eigenvalues.\n\\[\n\\lambda^{2}=8 \\Rightarrow \\lambda= \\pm \\sqrt{8}= \\pm 2 \\sqrt{2}\n\\]\n\\( \\therefore \\) a) The eigenvalues are \\( 2 \\sqrt{2} \\&-2 \\sqrt{2} \\).\n\nSnipra sanee\nSection 6\nDeate:\nsubslituing \\( y=-x-z \\) from eq (1)\n\\[\n\\begin{array}{rl}\na x+b y z & a x+(-x-z) b=a x-x h-z b \\\\\n& v=(a-b) x-b z \\rightarrow \\text { zhis is a linear comb of } \\\\\n& \\therefore v \\in \\operatorname{span}(x, z)\n\\end{array}\n\\]\n\\( \\therefore \\operatorname{span}(x, y) \\subseteq \\operatorname{span}(x, y) \\)\nnow uts consider another vector \\( v=a x+b z \\) in \\( \\operatorname{span}(x, z) \\) subs. \\( z=-x-y \\) from eq (1)\n\\[\n\\begin{array}{l} \nv=a x+b z=a x+b(-x-y) \\\\\n=a x-b x-b y \\\\\n=(a-b) x-b y \\\\\n\\therefore v \\in \\operatorname{span}(x, y)\n\\end{array}\n\\]\n\\( \\therefore \\operatorname{span}(x, y) \\subseteq \\operatorname{span}\\left(x, \\frac{\\pi}{g}\\right) \\)\n\\[\n\\therefore \\operatorname{span}(x, y)=\\operatorname{span}(x, z)\n\\]\n\\( \\Rightarrow \\Rightarrow L o \\operatorname{snow} \\operatorname{span}(x, z)=\\operatorname{span}(y, z) \\)\n\\( \\Rightarrow \\) rets consider any vector \\( v=a x+b z \\) in \\( \\operatorname{span}(x, z) \\)\nsubs \\( x=-y-z \\) from eq (1)\n\\[\n\\begin{aligned}\nv=a x+b z & =a(-y-z)+b z \\\\\n& =-a y-a z+b z \\\\\n& =(b-a) z-a y\n\\end{aligned}\n\\]\n\\( v \\in \\operatorname{span}(y, z) \\)\n\\( \\therefore \\quad \\operatorname{span}(g, x) \\subseteq \\operatorname{span}\\left(g^{x}, z\\right) \\)\n\\( \\Rightarrow \\) now ets consider another vector \\( v z \\) ay \\( +b z \\) in span \\( (y, z) \\) subs \\( y=-x-z \\) from eq (1)\n\\[\n\\begin{array}{l}\nv=a y+b z=a(-x-z)+b z z-a x-a z+b y z \\\\\n\\quad z(b-a) z-a x \\\\\n\\therefore v \\in \\operatorname{span}(x, z) \\\\\n\\therefore \\operatorname{span}(x, z) \\subseteq \\operatorname{span}(y, z)\n\\end{array}\n\\]\n\nSnipra Saher\nSection 6\nDate\n\\[\n\\therefore \\operatorname{span}(x, z)=\\operatorname{span}(y, z)\n\\]\nfrom eq (2) \\& (3), we can conclude.\n\\[\n\\operatorname{span}(x, y)=\\operatorname{span}(x, z)=\\operatorname{span}(y, z)] \\text { Hence proud? }\n\\]\nb) Suppose the wectors \\( v_{1}, v_{2} \\ldots v_{n} \\) span \\( v \\). We need to show that the wetors \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{1}, \\ldots v_{n}-v_{1} \\) also span \\( V \\).\n\\( \\rightarrow \\) since \\( v_{1}, v_{2} \\ldots v_{n} \\operatorname{span} v \\), any weetor \\( v \\in v \\) coin be urititen as a linear combination of \\( v_{1} \\ldots v_{n} \\).\n\\[\nv_{2} a_{1} v_{1}+a_{2} v_{2}+\\cdots+a_{n} v_{n}\n\\]\nlets take \\( v_{2}=\\left(v_{2}-v_{1}\\right)+v_{1} \\)\n\\[\n\\begin{array}{c}\nv_{3}=\\left(v_{3}-v_{1}\\right)+v_{1} \\\\\n\\vdots \\\\\nv_{n}=\\left(v_{n}-v_{1}\\right)+v_{1}\n\\end{array}\n\\]\nsubstifuting these in eq(1).\n\\[\n\\left.v=a_{1} v_{1}+a_{2}\\left(\\left(v_{2}-v_{1}\\right)+v_{1}\\right)+\\cdots+a_{n}\\left(\\left(v_{n}-v_{1}\\right)+v_{1}\\right)\\right)\n\\]\nsimplifying this wiel give:\n\\[\nv_{2}\\left(a_{1}+a_{2}+\\cdots+a_{n}\\right) v_{1}+a_{2}\\left(v_{2}-v_{1}\\right)+\\cdots+a_{n}\\left(v_{n}-v_{1}\\right)\n\\]\nsince \\( v \\) is the rinear combination of \\( v_{1}, v_{2}-v_{1}, \\ldots \\) . \\( v_{n}-v_{1} \\), they also span \\( V \\).\n\\( \\rightarrow \\) Linear Independence:\nSince \\( v_{1}, v_{2} \\ldots v_{n} \\) are linearly independent. This means\n\nShipra Sahes\nSection 6\nDate\nb) now \\( \\frac{\\lambda_{\\max }}{\\lambda_{\\min }}{ }^{2} \\) ?\n\\( \\because \\) the eigenvalues are \\( 2 \\sqrt{2} \\&-2 \\sqrt{2} \\).\n\\( \\lambda_{\\max }=2 \\sqrt{2} \\)\n\\( \\lambda \\min =-2 \\sqrt{2} \\)\n\\( \\therefore \\frac{\\lambda_{\\max }}{\\lambda_{\\min }}=\\frac{2 \\sqrt{2}}{-2 \\sqrt{2}}=-1 \\)\nInough eigenvalues are mostly considered in absolute torms i.e just the magnitude.\n\\[\n\\left|\\lambda_{\\min }\\right|=2 \\sqrt{2},\\left|\\lambda_{\\text {max }}\\right|=2 \\sqrt{2}\n\\]\n\nThus, the ratio \\( \\lambda \\max \\) Amin in terms of magnitude\n\\[\n\\text { is } \\frac{\\lambda_{\\text {max }}}{\\lambda_{\\min }}=1\n\\]\n\nQSo a) Let \\( x, y, z \\) be three wectors in a vector space \\( v \\). Show that if \\( x+y+z=0 \\), then \\( \\operatorname{span}\\{x, y\\}=\\operatorname{span}\\{x, z) \\) \\( =\\operatorname{span}\\{y, x\\} \\).\nb) Suppose the wectors \\( v_{1}, v_{2} ; v_{n} \\) span \\( v \\). Show that the vectors \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{1}, \\ldots v_{n}-v_{1} \\) also span \\( v \\). Showenat if \\( v_{1}, v_{2} \\ldots v_{n} \\) are linearly independent, \\( v_{1}, v_{2}-v_{1} \\), ... \\( v_{n}-v_{1} \\) are also vinearly independent.\n\\( \\rightarrow \\) a) Given 3 vectors \\( x, y, z \\) in a wetor space \\( v \\) such that\n\\[\nx+y+z=0\n\\]\nwe need to snow, \\( \\operatorname{span}(x y)=\\operatorname{span}(y, z)=\\operatorname{span}(x, z) \\).\n\\( \\Rightarrow \\) Lo show, \\( \\operatorname{span}(x, y)=\\operatorname{span}(x, z) \\)\nwe need to show \\( \\operatorname{span}(x, y) \\leqslant \\operatorname{span}(x, r) \\)\n\\( \\& \\operatorname{span}(x, z) C \\operatorname{span}(x, y) \\).\nnow lets consider a wetor \\( v=a x+b y \\) in \\( \\operatorname{span}(x, y) \\).\n\nSnipra sany section 6\n\nDate: \\( \\qquad \\)\nthe only Solution to:\n\\[\nc_{1} v_{1}+c_{2} v_{2}+\\cdots+c_{n} v_{n}=0 \\text { is } c_{1} c_{2}=c_{n}=0\n\\]\n\\( \\Rightarrow \\) we need to show that \\( v_{1}, v_{2}-v_{1}, \\ldots v_{n}-v_{1} \\) are also - linearly independent.\n\nConsider the eq\":\n\\[\n\\begin{array}{ll}\n\\Rightarrow & c_{1} v_{1}+c_{2}\\left(v_{2}-v_{1}\\right)+\\cdots+c_{n}\\left(v_{n}-v_{1}\\right)=0 \\\\\n\\Rightarrow & c_{1} v_{1}+c_{2} v_{2}-c_{2} v_{1}+\\cdots+c_{n} v_{n}-c_{n} v_{1}=0 \\\\\n\\Rightarrow & c_{1} v_{1}+c_{2} v_{2}+c_{3} v_{3}+\\cdots+c_{n} v_{n}-\\left(c_{2}+c_{3}+c_{4}+\\cdots+c_{n}\\right) v_{1}=0 \\\\\n\\Rightarrow & \\left(c_{1}-c_{2}-c_{3} \\cdots-c_{n}\\right) v_{1}+c_{2} v_{2}+c_{3} v_{3}+\\cdots+c_{n} v_{n}=0\n\\end{array}\n\\]\n\nSince \\( v_{1}, v_{2}, v_{n} \\) are linearly independent, cach coeff must be tero.\n\\[\n\\begin{array}{l}\nc_{1}-c_{2}-c_{3} \\cdots-\\cdots c_{n}=0 \\\\\nc_{2}=0 \\\\\nc_{3}=0\n\\end{array}\n\\]\n\\[\n\\mathrm{c}_{n}=0\n\\]\n\\( \\Rightarrow \\) Bysubstituting ar the values, we get \\( c_{1}=0 \\). Thus\n\\( c_{1}=c_{2}=\\cdots=c_{n}=0 \\), prosing that \\( v_{1}, v_{2}-v_{1}, \\ldots \\) \\( v_{n}-v_{1} \\) arealso linearly independent.\n\\( \\therefore v_{1}, v_{2}-v_{1}, v_{n}-v_{1} \\) are linearly independent.\n\\( \\rightarrow \\) Plence prowed!"